{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYlwwegdNs67MamDUnBOXc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/riya461/Learn_ML/blob/main/Algorithms/Backpropogation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ \\mathbf{a}^{(n)} = \\sigma(\\mathbf{z}^{(n)}) $$\n",
        "$$ \\mathbf{z}^{(n)} = \\mathbf{W}^{(n)}\\mathbf{a}^{(n-1)} + \\mathbf{b}^{(n)} $$\n",
        "\n",
        "\n",
        "$$ \\sigma(\\mathbf{z}) = \\frac{1}{1 + \\exp(-\\mathbf{z})} $$\n"
      ],
      "metadata": {
        "id": "veeC4lmlLqgU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Backpropagation can be used for both classification and regression problems\n",
        "\n",
        "In classification , best results are achieved when the network has one neuron in the output layer for each class value.\n",
        "\n",
        "One Hot Encoding - A binary classification problem with the class values of A and B. These expected outputs would have to be transformed into binary vectors with one column for each class value. Such as [1, 0] and [0, 1] for A and B respectively."
      ],
      "metadata": {
        "id": "m157Q6z3aARw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Neural Network"
      ],
      "metadata": {
        "id": "4qgGeUuqTgoP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Initialize network\n",
        "2. Forward propogate\n",
        "3. Back propogate error\n",
        "4. Train network\n",
        "5. Predict"
      ],
      "metadata": {
        "id": "wjHKtU9iVHXt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neuron\n",
        "- each has a set of weights need to be maintained\n",
        "- one weight for each input\n",
        "- additional weight for bias\n",
        "- dictionary to represent each neuron\n",
        "\n",
        "### Network\n",
        "- organised into layers\n",
        "- input layer - row from our training dataset\n",
        "- then a hidden layer\n",
        "- followed by output layer - one neuron for each class value\n",
        "\n",
        "**Layers as arrays of dictionaries **\n",
        "\n",
        "**Whole network as an array of layers **\n",
        "\n"
      ],
      "metadata": {
        "id": "edXggAfKVbd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import random,seed\n",
        "from math import exp"
      ],
      "metadata": {
        "id": "BfvoW4GteLbT"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Initialise Network\n",
        "- create new neural network ready for training\n",
        "- 3 parameters\n",
        "  - number of input\n",
        "  - number of neurons in hidden layer\n",
        "  - number of output\n",
        "- **n_hidden** neurons in hidden layer - each has **n_inputs + 1** weights for each neuron in hidden layer - one for each input column in dataset and one for bias\n",
        "- **n_outputs** neurons - each has **n_hidden + 1** weights\n",
        "\n"
      ],
      "metadata": {
        "id": "elYK26NOan49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
        "  network = list()\n",
        "  hidden_layer = [ {'weights':\n",
        "                    [random() for i in range(n_inputs + 1)]}\n",
        "                   for i in range(n_hidden)\n",
        "                   ]\n",
        "  network.append(hidden_layer)\n",
        "  output_layer = [ {'weights':\n",
        "                    [random() for i in range(n_hidden + 1)]}\n",
        "                   for i in range(n_outputs)\n",
        "                   ]\n",
        "  network.append(output_layer)\n",
        "  return network"
      ],
      "metadata": {
        "id": "QDaNtnAfdOql"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed(1)\n",
        "network = initialize_network(2,1,2)\n",
        "for layer in network:\n",
        "  print(layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3g4JIMMeCj4",
        "outputId": "35d709d9-107c-4265-d5f8-c21e93eaec69"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}]\n",
            "[{'weights': [0.2550690257394217, 0.49543508709194095]}, {'weights': [0.4494910647887381, 0.651592972722763]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Forward propogate\n",
        "- calculate output from a neural network by propogating an inout signal through each ayer until output layer output its values\n",
        "\n",
        "1. Neuron Activation\n",
        "2. Neuron Transfer\n",
        "3. Forward Propogation"
      ],
      "metadata": {
        "id": "yf4UaGHIdSz1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neuron activation\n",
        "- input - row from training dataset or output from each neuron in hidden layer\n"
      ],
      "metadata": {
        "id": "vr0vo7BhfwLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neuron activation - weighted sum of inputs\n",
        "def activate(weights,inputs):\n",
        "  print(\"weights\",len(weights))\n",
        "  print(\"input\",len(inputs))\n",
        "  activation = weights[-1] # bias is here assumed as the last weight in list\n",
        "  for i in range(len(weights)-1):\n",
        "    print(i)\n",
        "    activation += weights[i] * inputs[i]\n",
        "  return activation\n"
      ],
      "metadata": {
        "id": "6UjYnW5Sekq7"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neuron Transfer\n",
        "- traditionally sigmoid activation function ( logistic ) but also can use `tanh` - hyperbolic , rectifier transfer function etc\n",
        "- Sigmoid - 0-1 between value\n"
      ],
      "metadata": {
        "id": "e0KeR-hVgJ57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neuron Transfer\n",
        "def transfer(activation):\n",
        "  return 1.0/1.0 + exp(-activation)"
      ],
      "metadata": {
        "id": "M7lIMpKffbQH"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Forward Propogation\n",
        "- output from one layer become input to neurons on next layer"
      ],
      "metadata": {
        "id": "DqT6wnjHgxLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward propogation\n",
        "def forward_propagate(network, row):\n",
        "  inputs = row\n",
        "  for layer in network:\n",
        "    new_inputs = []\n",
        "    for neuron in layer:\n",
        "      activation = activate(neuron['weights'], inputs)\n",
        "      neuron['output'] = transfer(activation)\n",
        "      new_inputs.append(neuron['output'])\n",
        "    inputs = new_inputs\n",
        "  return inputs"
      ],
      "metadata": {
        "id": "x68t0iBYhqDg"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "seed(1)\n",
        "network = initialize_network(2,1,2)\n",
        "for layer in network:\n",
        "  print(layer)\n",
        "row = [1,0, None ]\n",
        "output = forward_propagate(network,row)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUv-jg4ZiY6-",
        "outputId": "9e376909-1532-4b98-87d2-2b10653886ea"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}]\n",
            "[{'weights': [0.2550690257394217, 0.49543508709194095]}, {'weights': [0.4494910647887381, 0.651592972722763]}]\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 2\n",
            "input 1\n",
            "0\n",
            "weights 2\n",
            "input 1\n",
            "0\n",
            "[1.425538171328089, 1.2768792176668917]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "None of the values makes sense now"
      ],
      "metadata": {
        "id": "DfzC1kVltkWG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Back Propogate Error\n",
        "\n",
        "1. Transfer Derivative\n",
        "2. Error Backpropogation"
      ],
      "metadata": {
        "id": "0MdU7JevtnnO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transfer Derivative\n",
        "- output from a neuron - calculate it's slope\n",
        "- using sigmoid transfer function"
      ],
      "metadata": {
        "id": "goVWhOzZ5_O5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transfer_derivative(output):\n",
        "  return output * (1.0 - output)"
      ],
      "metadata": {
        "id": "_3USwEAotkIF"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Error Backpropogation\n",
        "- expected : the expected output value for neuron\n",
        "- output : value for neuron\n",
        "- transfer_derivative() : calculates slope of neuron's output value\n",
        "\n",
        "- **error_j** : error signal from jth neuron\n",
        "- **weight_k** : weight that connects kth neuron to current"
      ],
      "metadata": {
        "id": "25FGOyul6WNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_propagate_error(network, expected):\n",
        "  for i in reversed(range(len(network))):\n",
        "    layer = network[i]\n",
        "    errors = list()\n",
        "    if i != len(network)-1:\n",
        "      for j in range(len(layer)):\n",
        "        error = 0.0\n",
        "        for neuron in network[i + 1]:\n",
        "          error += (neuron['weights'][j] * neuron['delta'])\n",
        "          errors.append(error)\n",
        "    else:\n",
        "      for j in range(len(layer)):\n",
        "        neuron = layer[j]\n",
        "        errors.append(neuron['output'] - expected[j])\n",
        "      for j in range(len(layer)):\n",
        "        neuron = layer[j]\n",
        "        neuron['delta'] = errors[j] * transfer_derivative(neuron['output'])"
      ],
      "metadata": {
        "id": "cMSmc0UV8Bf-"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network = [[{'output': 0.7105668883115941, 'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}],\n",
        " [{'output': 0.6213859615555266, 'weights': [0.2550690257394217, 0.49543508709194095]}, {'output': 0.6573693455986976, 'weights': [0.4494910647887381, 0.651592972722763]}]]\n",
        "expected = [0, 1]\n",
        "backward_propogate_error(network, expected)\n",
        "for layer in network:\n",
        "  print(layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va4TLDpV8DzK",
        "outputId": "33c1b1e9-3d6d-4305-de5f-5850bb5d359d"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'output': 0.7105668883115941, 'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}]\n",
            "[{'output': 0.6213859615555266, 'weights': [0.2550690257394217, 0.49543508709194095], 'delta': 0.14619064683582808}, {'output': 0.6573693455986976, 'weights': [0.4494910647887381, 0.651592972722763], 'delta': -0.0771723774346327}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Network\n",
        "\n",
        "- trained using stochastic gradient descent\n",
        "- involves multiple iterations\n",
        "\n",
        "1. Update Weights\n",
        "2. Train Network\n",
        "\n",
        "**Stochastic gradient descent**\n"
      ],
      "metadata": {
        "id": "ROX29TjB9SNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Update Weights\n",
        "# learning_rate - control how much to change weight to correct for error\n",
        "# error - calculated by backpropogation procedure for neuron\n",
        "# input - value that caused the error\n",
        "def update_weights(network, row, l_rate):\n",
        "  for i in range(len(network)):\n",
        "    inputs = row[:-1]\n",
        "    if i != 0:\n",
        "      inputs = [neuron['output'] for neuron in network[i - 1]]\n",
        "      for neuron in network[i]:\n",
        "        for j in range(len(inputs)):\n",
        "          neuron['weights'][j] -= l_rate * neuron['delta'] * inputs[j]\n",
        "          neuron['weights'][-1] -= l_rate * neuron['delta']"
      ],
      "metadata": {
        "id": "w-m4zY-K8nmw"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train a network for a fixed number of epochs\n",
        "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
        "  for epoch in range(n_epoch):\n",
        "    sum_error = 0\n",
        "  for row in train:\n",
        "    outputs = forward_propagate(network, row)\n",
        "    expected = [0 for i in range(n_outputs)]\n",
        "    expected[row[-1]] = 1\n",
        "    sum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
        "    backward_propagate_error(network, expected)\n",
        "    update_weights(network, row, l_rate)\n",
        "    print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
        ""
      ],
      "metadata": {
        "id": "GYft7oqiQ61K"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Test training backprop algorithm\n",
        "seed(1)\n",
        "dataset = [[2.7810836,2.550537003,0],\n",
        " [1.465489372,2.362125076,0],\n",
        " [3.396561688,4.400293529,0],\n",
        " [1.38807019,1.850220317,0],\n",
        " [3.06407232,3.005305973,0],\n",
        " [7.627531214,2.759262235,1],\n",
        " [5.332441248,2.088626775,1],\n",
        " [6.922596716,1.77106367,1],\n",
        " [8.675418651,-0.242068655,1],\n",
        " [7.673756466,3.508563011,1]]\n",
        "n_inputs = len(dataset[0]) - 1\n",
        "n_outputs = len(set([row[-1] for row in dataset]))\n",
        "network = initialize_network(n_inputs, 2, n_outputs)\n",
        "train_network(network, dataset, 0.5, 20, n_outputs)\n",
        "for layer in network:\n",
        "  print(layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKq4toCwRALz",
        "outputId": "31541aa9-4ddb-4896-90fd-6500fb230369"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            ">epoch=19, lrate=0.500, error=1.610\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            ">epoch=19, lrate=0.500, error=2.855\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            ">epoch=19, lrate=0.500, error=4.073\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            ">epoch=19, lrate=0.500, error=5.213\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            ">epoch=19, lrate=0.500, error=6.358\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            ">epoch=19, lrate=0.500, error=7.680\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            ">epoch=19, lrate=0.500, error=8.881\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            ">epoch=19, lrate=0.500, error=10.040\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            ">epoch=19, lrate=0.500, error=11.151\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            ">epoch=19, lrate=0.500, error=12.276\n",
            "[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614], 'output': 1.0084962722566237}, {'weights': [0.2550690257394217, 0.49543508709194095, 0.4494910647887381], 'output': 1.0158419487779027}]\n",
            "[{'weights': [1.0087353321806103, 1.1497965258250098, 0.7798611133951926], 'output': 1.0589303965281214, 'delta': -0.06608063278615245}, {'weights': [0.431143883619416, 1.2599667148984421, 1.2087984283464521], 'output': 1.0540799741002167, 'delta': -0.003082808248749094}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict\n",
        "- class prediction\n",
        "- class value largest possibility\n",
        "- arg max function"
      ],
      "metadata": {
        "id": "hCyq0SknTdZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(network, row):\n",
        " outputs = forward_propagate(network, row)\n",
        " return outputs.index(max(outputs))"
      ],
      "metadata": {
        "id": "9gDUDc-VSCQU"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for row in dataset:\n",
        " prediction = predict(network, row)\n",
        " print('Expected=%d, Got=%d' % (row[-1], prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QLfgTnYT1kd",
        "outputId": "cb81ec16-27d9-4f34-f737-105f7109358f"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "Expected=0, Got=1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "Expected=0, Got=1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "Expected=0, Got=1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "Expected=0, Got=1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "Expected=0, Got=1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "Expected=1, Got=1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "Expected=1, Got=1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "Expected=1, Got=1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "Expected=1, Got=1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 3\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "weights 3\n",
            "input 2\n",
            "0\n",
            "1\n",
            "Expected=1, Got=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LCVTJWsXT17_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}